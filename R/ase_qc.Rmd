---
title: "Allele Specific Expression Quality Control"
subtitle: "210408_psen1_fADfAI dataset"
author: "Lachlan Baer"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: flatly
    toc: true
    toc_float: true
    toc_depth: 4
    fig_width: 8
    fig_height: 6
    fig_align: "center"
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  error = FALSE, 
  fig.align = "center"
)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

# Setup 

```{r packages}
suppressPackageStartupMessages({
  ## Common
  library(tidyverse)
  library(magrittr)
  library(future.apply)
  library(here)
  library(AnnotationHub)
  library(purrr)
  library(scales)
  library(kableExtra)
  library(tictoc)
  library(ggrepel)
  library(RColorBrewer)
  library(ggpubr)
  library(pander)
  library(rmarkdown)
  ## Project specific
  library(UpSetR)
  library(SeqArray)
  library(ngsReports)
})
```

```{r options}
if (interactive()) setwd(here::here())
theme_set(theme_bw())
cores <- availableCores() - 1
```

```{r}
source("~/bioinformatics/bioToolkit/lbFuncs.R")
```

```{r}
## Choose either local or remote project directory
# projDir <- here()
projDir <- "/hpcfs/users/a1647910/210408_psen1_fADfAI"
```

## EnsDb

```{r}
ah <- AnnotationHub() %>%
  subset(species == "Danio rerio") %>%
  subset(rdataclass == "EnsDb")
ensDb <- ah[["AH83189"]] ## Ens101
genes <- genes(ensDb)
mcols(genes) <- mcols(genes)[
  c("gene_id", "gene_name", "gene_biotype", "entrezid")
]
exons <- exonsBy(ensDb, by = "gene")
```

An `EnsDb` object for Ensembl release 101 was setup for extracting gene and exon annotation information.

## Metadata

```{r}
metadata <- read_csv(file.path(projDir, "files/samples.csv")) %>%
  dplyr::select(-sample) %>%
  mutate(
    Genotype = factor(Genotype, levels = unique(Genotype)),
    basename = factor(basename, levels = basename),
    alias = c(
      paste0(rep("fAD", 7), seq(1, 7)),
      paste0(rep("fAI", 8), seq(1, 8)),
      paste0(rep("wt", 9), seq(1, 9))
    )
  ) %>%
  dplyr::select(sample = basename, fish_id, batch_killed, sex = Sex, RINe,
                genotype = Genotype, genotype_2 = Genotype_2, alias)
metadata %>%
  dplyr::select(
    Sample = sample, Genotype = genotype, Alias = alias, Gender = sex,
    `Fish ID` = fish_id, `Batch Killed` = batch_killed
  ) %>%
  kable(
    align = "l",
    caption = "Sample metadata"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive")
  )
genoCols <- metadata$genotype %>%
  levels() %>%
  length() %>%
  brewer.pal("Set1") %>%
  setNames(levels(metadata$genotype))
compCols <- genoCols[1:2]
```

```{r}
drChrs <- seq(1:25)
```

# GATK short variant discovery

The [GATK best practices workflow for short variant discovery](https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels-) was followed to produce variants calls in `VCF` format from raw RNA-seq `FASTQ` data.
The following document describes the workflow and modifications implemented to reach the end goal of accurate allelic read counts for measurement of Allele Specific Expression (ASE).

## Duplicates

Marking duplicates is important because almost all statistical models for variant calling assume some sort of independence between measurements.
Duplicates that arise from PCR artifacts are not independent.
Aligned reads were classified into duplicate groups based on their genomic coordinates and UMI sequence.
This was performed with `UMI-tools group`, which tagged duplicate groups in the `BAM` file with the same `BX` tags.
`Picard MarkDuplicates` was used to mark duplicates assigned to groups with the `--BARCODE_TAG` option.
`MarkDuplicates` was set up to select the representative read for each group at random, as opposed to a base quality scoring strategy, such that reference allele mapping bias was avoided for downstream Allele Specific Expression (ASE) testing.

```{r}
dupeMetrics <- list.files(
  file.path(projDir, "analysis-variants/07_markDuplicates/samstats"),
  full.names = TRUE
) %>%
  lapply(function(x){
    sample <- basename(x) %>%
      str_remove(".tsv")
    metrics <- read_lines(x)
    grep("^SN", metrics, value = TRUE) %>%
      str_split("\t", simplify = TRUE) %>%
      .[, 2:3] %>%
      set_colnames(c("metric", "value")) %>%
      as_tibble() %>%
      mutate(metric = str_remove(metric, ":$")) %>%
      pivot_wider(names_from = "metric", values_from = "value") %>%
      mutate(
        across(everything(), as.numeric),
        sample = sample,
        percent.duplication = `reads duplicated` / `reads mapped and paired`
      )
  }) %>%
  bind_rows()
```

Between `r pander(range(percent_format(0.01)(dupeMetrics$percent.duplication)))` of reads were marked as duplicates across all samples.

## Base quality score recalibration

Base quality score recalibration (BQSR) is a recommended technique in the `GATK` workflow which is used to assign accurate confidence scores to each sequenced base.
Real data contains systematic biases due to artifacts of sample preparation, sequencing and mapping.
BQSR aims to correct for the range of these types of artifacts, as downstream tools rely on base qualities to weigh the variant calls they make.
The process involves two keys steps performed by tools `BaseRecalibrator` and `ApplyBQSR` in the `GATK` suite.

**BaseRecalibrator**

`BaseRecalibrator` builds a model of covariation based on the input data and a set of known variants.
The set of known variants for this analysis was retrieved from the [Ensembl Variation database](https://asia.ensembl.org/info/genome/variation/index.html).
It is also possible to generate a set of known variants from the data itself if a reference is not available.
Details about this procedure are described [here](https://gatk.broadinstitute.org/hc/en-us/articles/360035890531-Base-Quality-Score-Recalibration-BQSR-).
`BaseRecalibrator` records data about the following features of aligned bases:

- Read group
- Quality score
- Machine cycle producing the base (Nth cycle = Nth base from the start of the read)
- Dinucleotide context (current base + previous base)

For each bin, the number of bases and how often such bases mistmatch the reference are counted and exported as a recalibration report.

**ApplyBQSR**

`ApplyBQSR` uses the recalibration file to go through the reads and adjust each base's score depending on what bins it falls in.
The new quality score is effectively determined by:

- The sum of the global difference between reported quality scores and the empirical quality
- plus the quality bin specific shift
- plus the cycle x quality and dinucleotide x quality effect

Recalibration should cause the read quality scores to match their empirical scores much closer than before.
This allows for more statistically robust downstream variant calling.

```{r}
files <- list.files(
  file.path(projDir, "analysis-variants/04_addRG/samstats"),
  full.names = TRUE
)
beforeRecalMetrics <- lapply(files, read_lines) %>%
  set_names(str_remove(basename(files), ".tsv"))
beforeRecalSummary <- map2(beforeRecalMetrics, files, function(.x, .y){
  grep("^SN", .x, value = TRUE) %>%
    str_split("\t", simplify = TRUE) %>%
    .[, 2:3] %>%
    set_colnames(c("metric", "value")) %>%
    as_tibble() %>%
    mutate(metric = str_remove(metric, ":$")) %>%
    pivot_wider(names_from = "metric", values_from = "value") %>%
    mutate(
      across(everything(), as.numeric),
      sample = str_remove(basename(.y), ".tsv")
    )
}) %>%
  bind_rows()
beforeRecalQuality <- map2(beforeRecalMetrics, files, function(.x, .y){
  grep("^FFQ", .x, value = TRUE) %>%
    str_split("\t", simplify = TRUE) %>%
    .[,-1] %>%
    set_colnames(c("cycle", paste0("BQ", seq(0, ncol(.) - 2)))) %>%
    as_tibble() %>%
    mutate(across(everything(), as.numeric)) %>%
    .[, colSums(.) != 0] %>%
    mutate(
      cycle = as.factor(cycle),
      sample = str_remove(basename(.y), ".tsv")
    ) 
})
```

```{r}
files <- list.files(
  file.path(projDir, "analysis-variants/09_bqsr/metrics"),
  full.names = TRUE
)
afterRecalMetrics <- lapply(files, read_lines) %>%
  set_names(str_remove(basename(files), ".tsv"))
afterRecalSummary <- map2(afterRecalMetrics, files, function(.x, .y){
  grep("^SN", .x, value = TRUE) %>%
    str_split("\t", simplify = TRUE) %>%
    .[, 2:3] %>%
    set_colnames(c("metric", "value")) %>%
    as_tibble() %>%
    mutate(metric = str_remove(metric, ":$")) %>%
    pivot_wider(names_from = "metric", values_from = "value") %>%
    mutate(
      across(everything(), as.numeric),
      sample = str_remove(basename(.y), ".tsv")
    )
}) %>%
  bind_rows()
afterRecalQuality <- map2(afterRecalMetrics, files, function(.x, .y){
  grep("^FFQ", .x, value = TRUE) %>%
    str_split("\t", simplify = TRUE) %>%
    .[,-1] %>%
    set_colnames(c("cycle", paste0("BQ", seq(0, ncol(.) - 2)))) %>%
    as_tibble() %>%
    mutate(across(everything(), as.numeric)) %>%
    .[, colSums(.) != 0] %>%
    mutate(
      cycle = as.factor(cycle),
      sample = str_remove(basename(.y), ".tsv")
    ) 
})
```

For successful recalibration it is critical that each read group (sample in this case) has more than 100 million aligned bases.
For this dataset the number of aligned bases ranged between `r pander(comma(range(pull(beforeRecalSummary, "bases mapped (cigar)"))))` across all samples, and therefore base recalibration was performed.

```{r}
files <- list.files(
  file.path(projDir, "analysis-variants/09_bqsr/recal"),
  pattern = "analyzeCovariates",
  full.names = TRUE
)
recalCovariates <- lapply(files, function(x){
  read_csv(x) %>%
    mutate(sample = str_remove(basename(x), ".analyzeCovariates.csv"))
})
```

To assess whether base recalibration was successful, base qualities were assessed before and after recalibration.
As all samples showed similar profiles, a representative sample for each genotype is shown below.

```{r, fig.height=4, fig.cap="*Reported base quality plotted against empirical quality. Base qualities before recalibration showed patterns of over-estimation by the sequencer. Post-recalibration quality scores fitted the empirically derived quality scores better than pre-recalibration. Additionally a greater distribution of quality scores was observed after recalibration procedures.*"}
lapply(recalCovariates[c(1, 9, 15, 19)], function(x){
  x %>%
    dplyr::filter(CovariateName == "QualityScore") %>%
    left_join(metadata[, c("sample", "genotype")]) %>%
    mutate(facet = paste(sample, "-", genotype))
}) %>%
  bind_rows() %>%
  ggplot(aes(AverageReportedQuality, EmpiricalQuality)) +
  geom_point(aes(colour = Recalibration), alpha = 0.7) +
  geom_abline(intercept = 0, slope = 1, linetype = 2) + 
  xlab("Reported Quality Score") +
  ylab("Empirical Quality Score") +
  scale_colour_manual(values = c("Before" = "maroon1", "After" = "blue")) +
  facet_wrap(~facet, nrow = 1) +
  theme(
    legend.position = "bottom",
    strip.text.x = element_text(size = 7)
  )
```

```{r, fig.height=4, fig.cap="*Residual error by machine cycle. Observations before recalibration are coloured pink and after recalibration are blue. Most cycles showed an overestimation of base qualities which was improved after recalibration.*"}
lapply(recalCovariates[c(1, 9, 15, 19)], function(x){
  x %>%
    dplyr::filter(CovariateName == "Cycle") %>%
    left_join(metadata[, c("sample", "genotype")]) %>%
    mutate(
      CovariateValue = factor(CovariateValue, levels = unique(CovariateValue)),
      facet = paste(sample, "-", genotype)
    )
}) %>%
  bind_rows() %>%
  ggplot(aes(CovariateValue, Accuracy)) +
  geom_point(aes(colour = Recalibration), alpha = 0.7)+
  geom_abline(intercept = 0, slope = 0, linetype = 2) + 
  xlab("Machine Cycle") +
  ylab("Quality Score Accuracy (Empirical - Reported)") +
  scale_colour_manual(values = c("Before" = "maroon1", "After" = "blue")) +
  scale_x_discrete(breaks = seq(0, 100, 5)) +
  coord_cartesian(ylim = c(-10, 10)) +
  facet_wrap(~facet, nrow = 1) +
  theme(
    legend.position = "bottom",
    strip.text.x = element_text(size = 7),
    axis.text.x = element_text(size = 6, angle = 270, hjust = 0)
  )
```

```{r, fig.height=4, fig.cap="*Residual error by dinucleotide. Observations before recalibration are coloured pink and after recalibration are blue. Dinucleotide contexts showed over-estimation of base qualities pre-recalibration but were substantially improved after recalibration.*"}
lapply(recalCovariates[c(1, 9, 15, 19)], function(x){
  x %>%
    dplyr::filter(CovariateName == "Context") %>%
    left_join(metadata[, c("sample", "genotype")]) %>%
    mutate(
      CovariateValue = factor(CovariateValue, levels = unique(CovariateValue)),
      facet = paste(sample, "-", genotype)
    )
}) %>%
  bind_rows() %>%
  ggplot(aes(CovariateValue, Accuracy, colour = Recalibration)) +
  geom_point(alpha = 0.7, shape = "\U2012", size = 5)+
  geom_abline(intercept = 0, slope = 0, linetype = 2) + 
  xlab("Dinucleotide") +
  ylab("Quality Score Accuracy (Empirical - Reported)") +
  scale_colour_manual(values = c("Before" = "maroon1", "After" = "blue")) +
  coord_cartesian(ylim = c(-10, 10)) +
  facet_wrap(~facet, nrow = 1) +
  theme(
    legend.position = "bottom",
    strip.text.x = element_text(size = 7),
    axis.text.x = element_text(size = 6, angle = 270, hjust = 0)
  )
```

## Genomic location

Variants were restricted to those that lie only in exonic regions of the Ensembl version 101 primary assembly.
For zebrafish this consists of chromosomes `r min(drChrs)` to `r max(drChrs)`.
To perform this within the `GATK`'s tools, an interval list was created containing the exonic ranges.
A number of interval list formats are supported by GATK as described [here](https://gatk.broadinstitute.org/hc/en-us/articles/360035531852-Intervals-and-interval-lists).
The GATK-style `.intervals` is poorly described but requires the format `<chr>:<start>-<end>` e.g. `1:1367-1367` for a singular base position. 
The nomenclature must match that of the chosen reference, for example, Ensembl labels chromosome 1 as "1", not "chr1".
The GATK-style format was chosen for its simplicity.

Defining intervals before calling variants also has the advantage of a large speed-up in computational processing time.
`HaplotypeCaller` is the longest step in the `GATK` short variant discovery pipeline, sometimes taking over a day to process for large datasets on a HPC system when interval lists are not utilised.

The construction of this interval list was implemented inside the `snakemake` workflow as a custom `R` script ([GitHub link](https://github.com/baerlachlan/210408_psen1_fADfAI/blob/master/analysis-variants/smk/scripts/intervals.R)).

## Variant calling

With the intention to perform downstream ASE analysis, initial variants were restricted to only biallelic SNVs.

Additionally, for RNA-seq data, the `GATK` recommends [specific hard filters](https://gatk.broadinstitute.org/hc/en-us/articles/360035890471-Hard-filtering-germline-short-variants).
Variants were removed with the following filters:

- QualByDepth: QD < 2.0
- Variant confidence (QUAL field) divided by the unfiltered depth of non-homozygous reference samples.
Removing variants that have a low QD normalises the variant quality and avoids inflation caused by deep coverage.
- FisherStrand: FS > 60.0
- The Phred-scaled probability there there is strand bias at the site.
Strand bias indicates whether the alternate allele was seen more or less often on the forward or reverse strand than the reference allele.
When there is little to no strand bias at the site, the FS value is close to 0.
- StrandOddsRatio: SOR > 4.0
- An alternative way to estimate strand bias using a test similar to the symmetric odds ratio test.
- RMSMappingQuality: MQ < 40.0
- Root mean square mapping quality over all the reads at the site.
- MappingQualityRankSumTest: MQRankSum < -12.5
- u-based z-approximation from the Rank Sum Test for mapping qualities.
This compares the mapping qualities of the reads supporting the reference allele and the alternate allele.
- ReadPosRankSumTest: ReadPosRankSum < -8.0
- u-based z-approximation from the Rank Sum Test for site position within reads.
This compares whether the positions of the reference and alternate alleles are different within the reads.

```{r}
calledMetrics <- list.files(
  path = file.path(projDir, "analysis-variants/10_variants/1_gvcf/log"),
  pattern = "detail",
  full.names = TRUE
) %>%
  lapply(read_tsv, comment = "#") %>%
  bind_rows() %>%
  dplyr::select(-contains(c("DBSNP", "DB_SNP", "NOVEL"))) %>%
  as.data.frame()
extractedMetrics <- list.files(
  path = file.path(projDir, "analysis-variants/10_variants/4_extract/log"),
  pattern = "detail",
  full.names = TRUE
) %>%
  lapply(read_tsv, comment = "#") %>%
  bind_rows() %>%
  dplyr::select(-contains(c("DBSNP", "DB_SNP", "NOVEL"))) %>%
  as.data.frame()
filteredMetrics <- list.files(
  path = file.path(projDir, "analysis-variants/10_variants/5_filter/log"),
  pattern = "detail",
  full.names = TRUE
) %>%
  lapply(read_tsv, comment = "#") %>%
  bind_rows() %>%
  dplyr::select(-contains(c("DBSNP", "DB_SNP", "NOVEL"))) %>%
  as.data.frame()
selectedMetrics <- list.files(
  path = file.path(projDir, "analysis-variants/10_variants/6_select/log"),
  pattern = "detail",
  full.names = TRUE
) %>%
  lapply(read_tsv, comment = "#") %>%
  bind_rows() %>%
  dplyr::select(-contains(c("DBSNP", "DB_SNP", "NOVEL"))) %>%
  as.data.frame()
```

```{r}
filtProgress <- calledMetrics %>%
  as_tibble() %>%
  dplyr::select(sample = SAMPLE_ALIAS, initial = TOTAL_SNPS)
filtProgress <- selectedMetrics %>%
  as_tibble() %>%
  dplyr::select(sample = SAMPLE_ALIAS, GATK = TOTAL_SNPS) %>%
  left_join(filtProgress)
```

After `GATK` recommended hard filters were applied the number of biallelic SNVs ready for ASE analysis ranged between `r pander(comma(range(filtProgress$GATK)))`.

# Allele Specific Expression

There are a number of important quality control measures that must be taken to ensure reliable data for allele specific expression (ASE) testing. 
The following procedures are based around the guidelines described in [Castel et al. Tools and Best Practices for allelic expression analysis.](https://www.biorxiv.org/content/biorxiv/early/2015/03/05/016097.full.pdf)

### WASP

Read mapping is a potential source of bias for ASE analysis.
For RNA-seq data mapped to a reference genome, reads that carry an alternate allele at positions of variation have at least one mismatch, and therefore a lower probability of aligning correctly than reads containing the reference allele.

`WASP` provides a suite of tools for unbiased allele-specific read mapping.
The `WASP` workflow for mappability filtering is defined by 5 steps:

1. Reads are mapped normally with the user's mapper of choice (`STAR` was chosen in this case).
2. Reads that overlap identified SNVs and therefore may have mapping bias are determined using `find_intersecting_snps.py` script.
Each overlapping read is output as a set of synthetic reads in `FASTQ` format with its allele swapped to to the other allele at the SNV site.
3. The set of allele-swapped reads are re-mapped using the same method and options used in step 1.
4. Reads where one or more allelic versions fail to map back to the same location are removed using `filter_remapped_reads.py` script.
5. Reads that did not overlap SNVs are merged with those that show unbiased mapping from step 4 using `samtools`, resulting in a complete set of mappability-filtered aligned reads in `BAM` format.

To begin the `WASP` filtering procedure, input files containing genetic variants (SNVs) previously identified by the `GATK` workflow are needed.
Since we do not have phasing information, it is recommended to use text-based format opposed to `HDF5` for the input files.
The text-based input files require three space-delimited columns (position, ref_allele, alt_allele), and one input file per chromosome.
The filenames must follow the convention `<chr>.snps.txt.gz` (e.g `1.snps.txt.gz` for chromosome 1).
This was implemented in the `snakemake` workflow as a custom `R` script.

Text-based input files were created within the `snakemake` workflow as a custom `R` script.
`WASP` filtering was subsequently performed on the HPC system.
The resulting `BAM` files were then ready for allele specific expression read counting with `ASEReadCounter`.

### ASEReadCounter

The `GATK`'s `ASEReadCounter` tool calculates allele counts at a set of positions after applying filters specifically tuned for ASE analysis of RNA-seq data.
The filters operate on mapping quality, base quality, depth of coverage and overlapping paired reads.
Each of these filters can be controlled by command-line arguments.
The data in this analysis was generated with the following options:

- `--min-mapping-quality 10`
- `--min-base-quality 20`
- `--count-overlap-reads-handling COUNT_FRAGMENTS_REQUIRE_SAME_BASE`
- Ths option counts all fragments where the base is consistent when mate pairs overlap.
- `--min-depth-of-non-filtered-base -1`
- This argument is disabled, because depth filtering was performed manually (see next section: Coverage).

`ASEReadCounter` was run on `BAM` alignment files that were subject to `WASP` filtering and also alignment files that had not been `WASP` filtered, to compare whether the filtering procedure improves any observable reference allele mapping bias.
Heterozygous SNVs detected by `ASEReadCounter` were recorded in separate `tsv` files for each sample. 
These were loaded into R as a list of tibbles containing allele count data for ASE analysis.

```{r}
files_nowasp <- list.files(
  file.path(projDir, "analysis-variants/12_aseRC/no_wasp"),
  full.names = TRUE
)
samples <- basename(files_nowasp) %>%
  str_remove(".tsv")
aseRC_nowasp <- lapply(files_nowasp, function(file){
  sample <- basename(file) %>%
    str_remove(".tsv")
  read_tsv(
    file,
    col_types = "cdcccdddddddd"
  ) %>%
    mutate(
      sample = sample,
      allele = paste0(refAllele, ",", altAllele)
    ) %>%
    left_join(metadata[,c("sample", "genotype")]) %>%
    dplyr::select(
      chromosome = contig, position, allele, refCount, altCount, totalCount,
      sample, genotype, lowMAPQDepth, lowBaseQDepth, rawDepth, otherBases,
      improperPairs, refAllele, altAllele
    )
}) %>% 
  set_names(samples)
```


```{r}
files_wasp <- list.files(
  file.path(projDir, "analysis-variants/12_aseRC/wasp"),
  full.names = TRUE
)
aseRC_wasp <- lapply(files_wasp, function(file){
  sample <- basename(file) %>%
    str_remove(".tsv")
  read_tsv(
    file,
    col_types = "cdcccdddddddd"
  ) %>%
    mutate(
      sample = sample,
      allele = paste0(refAllele, ",", altAllele)
    ) %>%
    left_join(metadata[,c("sample", "genotype")]) %>%
    dplyr::select(
      chromosome = contig, position, allele, refCount, altCount, totalCount,
      sample, genotype, lowMAPQDepth, lowBaseQDepth, rawDepth, otherBases,
      improperPairs, refAllele, altAllele
    )
}) %>% 
  set_names(samples)
```

```{r}
filtProgress <- list(
  nowasp = aseRC_nowasp %>%
    bind_rows() %>%
    group_by(sample) %>%
    summarise(
      aseRC = n()
    ) %>%
    left_join(filtProgress),
  wasp = aseRC_wasp %>%
    bind_rows() %>%
    group_by(sample) %>%
    summarise(
      software = n()
    ) %>%
    left_join(filtProgress)
)
```

### Coverage 

SNV sites with low read coverage are uninformative, and therefore were filtered.
To determine the optimal read coverage value for filtering, the effects of potential cut-offs were inspected.

```{r, eval=FALSE, include=FALSE}
# exonOverlaps_nowasp <- lapply(aseRC_nowasp, function(x){
#   indices <- x %>%
#     dplyr::select(seqnames = chromosome, start = position) %>%
#     mutate(end = start) %>%
#     makeGRangesFromDataFrame() %>%
#     findOverlaps(exons)
#   tibble(
#     snvInd = as.data.frame(indices)$queryHits,
#     geneInd = as.data.frame(indices)$subjectHits
#   )
# })
# coverageInfo_nowasp <- lapply(seq_along(aseRC_nowasp), function(x){
#   aseRC_nowasp[[x]][exonOverlaps_nowasp[[x]]$snvInd,] %>%
#     cbind(gene = names(exons[exonOverlaps_nowasp[[x]]$geneInd])) %>%
#     as_tibble() %>%
#     group_by(chromosome, position, allele, totalCount, sample, genotype) %>%
#     summarise(geneOverlaps = n()) %>%
#     ungroup()
# })
# exonOverlaps_wasp <- lapply(aseRC_wasp, function(x){
#   indices <- x %>%
#     dplyr::select(seqnames = chromosome, start = position) %>%
#     mutate(end = start) %>%
#     makeGRangesFromDataFrame() %>%
#     findOverlaps(exons)
#   tibble(
#     snvInd = as.data.frame(indices)$queryHits,
#     geneInd = as.data.frame(indices)$subjectHits
#   )
# })
# coverageInfo_wasp <- lapply(seq_along(aseRC_wasp), function(x){
#   aseRC_wasp[[x]][exonOverlaps_wasp[[x]]$snvInd,] %>%
#     cbind(gene = names(exons[exonOverlaps_wasp[[x]]$geneInd])) %>%
#     as_tibble() %>%
#     group_by(chromosome, position, allele, totalCount, sample, genotype) %>%
#     summarise(geneOverlaps = n()) %>%
#     ungroup()
# })
```

```{r}
covBins_nowasp <- lapply(aseRC_nowasp, function(x){
  n0 <- nrow(dplyr::filter(x, totalCount >= 0))
  n10 <- nrow(dplyr::filter(x, totalCount >= 10))
  n20 <- nrow(dplyr::filter(x, totalCount >= 20))
  n30 <- nrow(dplyr::filter(x, totalCount >= 30))
  n40 <- nrow(dplyr::filter(x, totalCount >= 40))
  n50 <- nrow(dplyr::filter(x, totalCount >= 50))
  sample <- unique(x$sample)
  tibble(
    bin = c("\u2265 0", "\u2265 10", "\u2265 20", "\u2265 30", "\u2265 40", "\u2265 50"),
    n = c(n0, n10, n20, n30, n40, n50),
    sample = sample,
    wasp = "Without WASP filtering"
  )
}) %>%
  bind_rows()
covBins_wasp <- lapply(aseRC_wasp, function(x){
  n0 <- nrow(dplyr::filter(x, totalCount >= 0))
  n10 <- nrow(dplyr::filter(x, totalCount >= 10))
  n20 <- nrow(dplyr::filter(x, totalCount >= 20))
  n30 <- nrow(dplyr::filter(x, totalCount >= 30))
  n40 <- nrow(dplyr::filter(x, totalCount >= 40))
  n50 <- nrow(dplyr::filter(x, totalCount >= 50))
  sample <- unique(x$sample)
  tibble(
    bin = c("\u2265 0", "\u2265 10", "\u2265 20", "\u2265 30", "\u2265 40", "\u2265 50"),
    n = c(n0, n10, n20, n30, n40, n50),
    sample = sample,
    wasp = "With WASP filtering"
  )
}) %>%
  bind_rows()
```

```{r, fig.height=4, fig.cap="*The number of SNVs per sample that satisfy read coverage cut-offs*"}
bind_rows(covBins_nowasp, covBins_wasp) %>%
  mutate(wasp = factor(wasp, levels = c(
    "Without WASP filtering", "With WASP filtering"
  ))) %>%
  ggplot(aes(bin, n, fill = bin)) +
  geom_boxplot() +
  labs(x = "Reads / SNV", y = "Number of SNVs") +
  theme(legend.position = "none") +
  facet_wrap(~wasp)
```

A cut-off of at least 10 counts per SNV position was applied, as it provides a reasonable estimate of ASE while keeping as many SNVs as possible.

```{r}
aseRC_wasp <- lapply(aseRC_wasp, function(x){
  dplyr::filter(x, totalCount >= 10)
})
aseRC_nowasp <- lapply(aseRC_nowasp, function(x){
  dplyr::filter(x, totalCount >= 10)
})
```

```{r}
filtProgress <- list(
  nowasp = aseRC_nowasp %>%
    bind_rows() %>%
    group_by(sample) %>%
    summarise(
      coverage = n()
    ) %>%
    left_join(filtProgress$nowasp),
  wasp = aseRC_wasp %>%
    bind_rows() %>%
    group_by(sample) %>%
    summarise(
      coverage = n()
    ) %>%
    left_join(filtProgress$wasp)
)
```

### Mono-allelic expression

Producing evidence of mono-allelic expression from short read RNA-seq datasets without parental genotypes or imprinting information is a controversial issue.
SNV sites were therefore filtered based on a depth criteria for each allele ($\ge$ 3 counts or $>$ 1% of the total counts for that allele).

```{r}
aseRC_wasp <- lapply(aseRC_wasp, function(x){
  dplyr::filter(
    x,
    refCount >= 3,
    altCount >= 3,
    refCount / totalCount > 0.01,
    altCount / totalCount > 0.01
  )
})
aseRC_nowasp <- lapply(aseRC_nowasp, function(x){
  dplyr::filter(
    x,
    refCount >= 3,
    altCount >= 3,
    refCount / totalCount > 0.01,
    altCount / totalCount > 0.01
  )
})
```

```{r}
filtProgress <- list(
  nowasp = aseRC_nowasp %>%
    bind_rows() %>%
    group_by(sample) %>%
    summarise(
      monoallelic = n()
    ) %>%
    left_join(filtProgress$nowasp),
  wasp = aseRC_wasp %>%
    bind_rows() %>%
    group_by(sample) %>%
    summarise(
      monoallelic = n()
    ) %>%
    left_join(filtProgress$wasp)
)
```

# Summary

### Reference mapping bias

`WASP` filtering is designed to remove the vast majority of reads with mapping bias.
Reference allele ratios were calculated for all SNVs passing filtering procedures with and without `WASP` filtering, to determine the effectiveness of `WASP`.
A residual mapping bias is indicated if reference allele ratios tend to deviate from 0.5.

```{r}
refRatios_nowasp <- lapply(aseRC_nowasp, function(x){
  x %>%
    dplyr::filter(totalCount != 0) %>%
    mutate(
      refRatio = refCount / totalCount,
      altRatio = altCount / totalCount,
      WASP = FALSE
    ) %>%
    dplyr::select(
      chromosome, position, allele, refRatio, altRatio, totalCount,
      sample, genotype, WASP
    )
}) %>%
  bind_rows()
```

```{r}
refRatios_wasp <- lapply(aseRC_wasp, function(x){
  x %>%
    dplyr::filter(totalCount != 0) %>%
    mutate(
      refRatio = refCount / totalCount,
      altRatio = altCount / totalCount,
      WASP = TRUE
    ) %>%
    dplyr::select(
      chromosome, position, allele, refRatio, altRatio, totalCount,
      sample, genotype, WASP
    )
}) %>%
  bind_rows()
```

Distributions of the reference allele ratio for all SNVs were visualised to determine if any mapping bias was present.
Distributions showing balanced profile without 0 or 1 inflation are representative of no mapping bias.

```{r, fig.cap="*Sample distributions of global reference allelic ratios for remaining SNVs when no WASP filtering was applied. Distributions are coloured by genotype. All samples tend to follow a similar distribution with inflations towards 1, indicating that a reference allele mapping bias is present.*"}
refRatios_nowasp %>%
  left_join(metadata[,c("sample", "genotype")]) %>%
  dplyr::arrange(genotype, sample) %>%
  ggplot(aes(refRatio, group = sample, colour = genotype)) +
  geom_density() +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  labs(x = "Reference allele ratio", y = "Density", colour = "Genotype") +
  theme(legend.position = "bottom") +
  scale_color_manual(values = genoCols) +
  ggtitle("Reference allele ratio distributions without WASP filtering")
```

```{r, fig.cap="*Sample distributions of global reference allelic ratios for remaining SNVs when WASP filtering was incorporated into the quality control procedure. Distributions are coloured by genotype. All samples show a reasonably balanced profile, indicating that WASP filtering successfully improved reference mapping bias.*"}
refRatios_wasp %>%
  left_join(metadata[,c("sample", "genotype")]) %>%
  dplyr::arrange(genotype, sample) %>%
  ggplot(aes(refRatio, group = sample, colour = genotype)) +
  geom_density() +
  geom_vline(xintercept = 0.5, linetype = "dashed") +
  labs(x = "Reference allele ratio", y = "Density", colour = "Genotype") +
  theme(legend.position = "bottom") +
  scale_color_manual(values = genoCols) +
  ggtitle("Reference allele ratio distributions with WASP filtering")
```

As an alternative viewpoint, boxplots of reference allele ratios were plotted for each sample.
Median/mean reference allele ratios that deviate substantially from 0.5 indicate a mapping bias.

```{r, fig.cap="*Boxplots showing reference allele ratios for remaining SNVs when no WASP filtering was applied. The mean reference ratio for each sample is indicated with a white dash, while the solid black line indicates a reference ratio of 0.5. Outliers are hidden for the ease of viewing. As indicated by mean and median reference ratios above 0.5, reference mapping bias is evident.*"}
refRatios_nowasp %>%
  left_join(metadata[,c("sample", "genotype")]) %>%
  dplyr::arrange(genotype, sample) %>%
  mutate(sample = factor(sample, levels = unique(sample))) %>%
  ggplot(aes(sample, refRatio, fill = genotype)) +
  geom_boxplot(fatten = 3, outlier.shape = NA) +
  geom_hline(yintercept = 0.5, colour = "black") +
  stat_summary(
    fun = mean, geom = "point", colour = "white", shape = "\U2012", size = 6
  ) +
  labs(x = "Sample", y = "Reference allele ratio") +
  scale_fill_manual(name = "Genotype", values = genoCols) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  theme(
    axis.text.x = element_text(angle = -90, vjust = 0.5),
    legend.position = "bottom"
  ) +
  ggtitle(label = "Reference allele ratios without WASP filtering")
```

```{r, fig.cap="*Boxplots showing reference allele ratios for remaining SNVs when WASP filtering was incorporated into the quality control procedure. The mean reference ratio for each sample is indicated with a white dash, while the solid black line indicates a reference ratio of 0.5. Outliers are hidden for the ease of viewing. Reference mapping bias was eliminated in WASP filtered data and presents a significant improvement over data that was not subject to WASP.*"}
refRatios_wasp %>%
  dplyr::filter(totalCount >= 10) %>%
  left_join(metadata[,c("sample", "genotype")]) %>%
  dplyr::arrange(genotype, sample) %>%
  mutate(sample = factor(sample, levels = unique(sample))) %>%
  ggplot(aes(sample, refRatio, fill = genotype)) +
  geom_boxplot(fatten = 3, outlier.shape = NA) +
  geom_hline(yintercept = 0.5, colour = "black") +
  stat_summary(
    fun = mean, geom = "point", colour = "white", shape = "\U2012", size = 6
  ) +
  labs(x = "Sample", y = "Reference allele ratio") +
  scale_fill_manual(name = "Genotype", values = genoCols) +
  scale_y_continuous(breaks = seq(0, 1, 0.1)) +
  guides(colour = FALSE) +
  theme(
    axis.text.x = element_text(angle = -90, vjust = 0.5),
    legend.position = "bottom"
  ) +
  ggtitle(label = "Reference allele ratios with WASP filtering")
```

`WASP` filtered data showed a marginally improved reference allele mapping bias and was chosen for ASE testing.

```{r}
aseRC <- aseRC_wasp
refRatios <- refRatios_wasp
filtStats <- filtProgress$wasp
```

```{r}
refBias <- refRatios %>%
  bind_rows() %>%
  group_by(sample) %>%
  summarise(mean = mean(refRatio), median = median(refRatio))
altBias <- refRatios %>%
  bind_rows() %>%
  group_by(sample) %>%
  summarise(mean = mean(altRatio), median = median(altRatio))
```

After quality control procedures, mean reference ratios ranged between `r round(min(refBias$mean), 3)` and `r round(max(refBias$mean), 3)`.
Median reference ratios ranged between `r round(min(refBias$median), 3)` and `r round(max(refBias$median), 3)`.
The mean reference ratios for each sample will be used as the null in statistical testing for ASE, as this can improve results [(Castel et al.)](https://www.biorxiv.org/content/biorxiv/early/2015/03/05/016097.full.pdf).

### Filtering

```{r, fig.cap="*Boxplots of the total number of SNVs remaining in each sample after various quality control filtering steps. The filters were applied sequentially from left to right across the x-axis.*"}
filtStats %>%
  dplyr::select(
    sample, `Within exons` = initial, GATK = GATK,
    `WASP/ASEReadCounter` = software,
    Coverage = coverage, `Mono-allelic expression` = monoallelic
  ) %>%
  pivot_longer(cols = -sample, names_to = "Filter", values_to = "SNVs") %>%
  mutate(Filter = factor(Filter, levels = unique(.$Filter))) %>%
  ggplot(aes(Filter, SNVs, group = Filter, fill = Filter)) +
  geom_boxplot() +
  labs(y = "Number of SNVs") +
  scale_y_continuous(labels = comma) +
  theme(
    legend.position = "none",
    axis.title.x = element_blank(),
    panel.grid.major.x = element_blank()
  )
```

### Coverage

```{r}
covPlotA <- lapply(aseRC, function(x){
  n10 <- nrow(dplyr::filter(x, totalCount >= 10))
  n20 <- nrow(dplyr::filter(x, totalCount >= 20))
  n30 <- nrow(dplyr::filter(x, totalCount >= 30))
  n40 <- nrow(dplyr::filter(x, totalCount >= 40))
  n50 <- nrow(dplyr::filter(x, totalCount >= 50))
  sample <- unique(x$sample)
  tibble(
    bin = c("\u2265 10", "\u2265 20", "\u2265 30", "\u2265 40", "\u2265 50"),
    n = c(n10, n20, n30, n40, n50),
    sample = sample
  )
}) %>%
  bind_rows() %>%
  ggplot(aes(bin, n, fill = bin)) +
  geom_boxplot() +
  labs(x = "Reads / SNV", y = "SNV count") +
  scale_y_continuous(
    breaks = seq(0, 100000, 10000),
    labels = comma
  ) +
  theme(
    legend.position = "none",
    panel.grid.major.x = element_blank()
  )
```

```{r}
exonOverlaps <- lapply(aseRC, function(x){
  indices <- x %>%
    dplyr::select(seqnames = chromosome, start = position) %>%
    mutate(end = start) %>%
    makeGRangesFromDataFrame() %>%
    findOverlaps(exons) %>%
    as.data.frame()
  tibble(
    snvInd = indices$queryHits,
    geneInd = indices$subjectHits
  )
})
aseRCByGene <- lapply(seq_along(aseRC), function(x){
  aseRC[[x]][exonOverlaps[[x]]$snvInd,] %>%
    cbind(gene = names(exons[exonOverlaps[[x]]$geneInd])) %>%
    as_tibble()
}) %>% 
  set_names(names(aseRC))
```

```{r}
covPlotB <- lapply(aseRCByGene, function(x){
  n10 <- length(unique(pull(dplyr::filter(x, totalCount >= 10), gene)))
  n20 <- length(unique(pull(dplyr::filter(x, totalCount >= 20), gene)))
  n30 <- length(unique(pull(dplyr::filter(x, totalCount >= 30), gene)))
  n40 <- length(unique(pull(dplyr::filter(x, totalCount >= 40), gene)))
  n50 <- length(unique(pull(dplyr::filter(x, totalCount >= 50), gene)))
  sample <- unique(x$sample)
  tibble(
    bin = c("\u2265 10", "\u2265 20", "\u2265 30", "\u2265 40", "\u2265 50"),
    n = c(n10, n20, n30, n40, n50),
    sample = sample
  )
}) %>%
  bind_rows() %>%
  ggplot(aes(bin, n, fill = bin)) +
  geom_boxplot() +
  labs(x = "Reads / SNV", y = "Gene count") +
  scale_y_continuous(
    breaks = seq(0, 10000, 1000),
    labels = comma
  ) +
  theme(
    legend.position = "none",
    panel.grid.major.x = element_blank()
  )
```

```{r}
covPlotC <- lapply(aseRCByGene, function(x){
  x %>%
    dplyr::select(chromosome, position, totalCount, sample, gene) %>%
    mutate(
      n10 = totalCount >= 10,
      n20 = totalCount >= 20,
      n30 = totalCount >= 30,
      n40 = totalCount >= 40,
      n50 = totalCount >= 50
    ) %>%
    group_by(gene) %>%
    summarise(
      n10 = sum(n10),
      n20 = sum(n20),
      n30 = sum(n30),
      n40 = sum(n40), 
      n50 = sum(n50)
    ) %>%
    ungroup() %>%
    pivot_longer(
      cols = c("n10", "n20", "n30", "n40", "n50"),
      names_to = "bin",
      values_to = "snvs"
    ) %>%
    group_by(bin, snvs) %>%
    summarise(genes = n()) %>%
    ungroup() %>%
    dplyr::filter(snvs != 0)
}) %>%
  bind_rows() %>%
  group_by(bin, snvs) %>%
  summarise(medianGenes = median(genes)) %>%
  ggplot(aes(snvs, medianGenes, colour = bin)) +
  geom_point() +
  geom_line() +
  scale_colour_discrete(
    labels = c("\u2265 10", "\u2265 20", "\u2265 30", "\u2265 40", "\u2265 50")
  ) +
  scale_x_continuous(minor_breaks = seq(0, 30, 1)) +
  scale_y_continuous(
    breaks = seq(0, 5000, 100),
    labels = comma
  ) +
  coord_cartesian(xlim = c(0, 20)) +
  labs(x = "SNVs / gene", y = "Median gene count", colour = "Coverage") +
  theme(legend.position= c(0.75, 0.75))
```

```{r, fig.height=4, fig.cap="*Genomic coverage of ASE data. **A**, **B** The number of SNVs (**A**) and protein coding genes (**B**) per sample at different read coverage cut-offs. **C** The number of protein coding genes against the number of SNVs they contain at different read coverage cut-offs. Each line represents the median value for all samples.*"}
ggarrange(covPlotA, covPlotB, covPlotC, nrow = 1, labels = "AUTO")
```

### Export

For static ASE testing, which describes the difference between two variants of a heterozygous allele in a single sample in an unchanging condition, `geneiASE` software was chosen.
`geneiASE` requires allele counts `tsv` format with four columns: featureID, snpID, alternative allele count, reference allele count. 
`tsv` files (one for each sample) were exported for ASE testing.

```{r, results="hide"}
staticCounts <- lapply(aseRCByGene, function(x){
  x %>%
    rownames_to_column("snvID") %>%
    left_join(altBias[,c("sample", "mean")]) %>%
    dplyr::select(
      gene, snvID, altCount, refCount, null.betabin.p = mean
    )
}) %>%
  set_names(samples)
lapply(seq_along(staticCounts), function(x){
  path <- file.path(
    "/hpcfs/users/a1647910/210408_psen1_fADfAI/analysis-variants/13_geneiase/1_counts",
    paste0(names(staticCounts[x]), ".static.tsv")
  )
  if (!file.exists(path)) {
    if (!dir.exists(dirname(path))) {
      dir.create(dirname(path), recursive = TRUE)
    }
    write_tsv(staticCounts[[x]], path)
  }
})
```

The final quality controlled ASE count data was also exported in case it was needed in further analysis.

```{r}
path <- here("files/aseRC.Rds")
if (!file.exists(path)) {
  saveRDS(aseRC, path)
}
```

```{r}
path <- here("files/aseRCByGene.Rds")
if (!file.exists(path)) {
  saveRDS(aseRC, path)
}
```

# Session information

```{r}
sessionInfo() %>%
  pander()
```

